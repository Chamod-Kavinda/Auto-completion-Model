{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda0e25f-476a-43c0-b3e7-f96a707be566",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# <center>Recurrent Neural Networks</center>\n",
    "## <center>Inclass Project 3 - MA4144</center>\n",
    "\n",
    "This project contains 10 tasks/questions to be completed, some require written answers. Open a markdown cell below the respective question that require written answers and provide (type) your answers. Questions that required written answers are given in blue fonts. Almost all written questions are open ended, they do not have a correct or wrong answer. You are free to give your opinions, but please provide related answers within the context.\n",
    "\n",
    "After finishing project run the entire notebook once and **save the notebook as a pdf** (File menu -> Save and Export Notebook As -> PDF). You are **required to upload this PDF on moodle**.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03930b71-f7aa-4eb8-a078-70fc89a1ac16",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Outline of the project\n",
    "\n",
    "The aim of the project is to build a RNN model to suggest autocompletion of half typed words. You may have seen this in many day today applications; typing an email, a text message etc. For example, suppose you type in the four letter \"univ\", the application may suggest you to autocomplete it by \"university\".\n",
    "\n",
    "![Autocomplete](https://d33v4339jhl8k0.cloudfront.net/docs/assets/5c12e83004286304a71d5b72/images/66d0cb106eb51e63b8f9fbc6/file-gBQe016VYt.gif)\n",
    "\n",
    "We will train a RNN to suggest possible autocompletes given $3$ - $4$ starting letters. That is if we input a string \"univ\" hopefully we expect to see an output like \"university\", \"universal\" etc.\n",
    "\n",
    "For this we will use a text file (wordlist.txt) containing 10,000 common English words (you'll find the file on the moodle link). The list of words will be the \"**vocabulary**\" for our model.\n",
    "\n",
    "We will use the Python **torch library** to implement our autocomplete model. \n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db6bc0-f7e0-473d-a172-e6579deea2ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the below cell to use any include any imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76fdc286-3211-4a8f-9802-29d28a324bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622b61b-dba8-47bb-8e07-92b77e78f4fa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Section 1: Preparing the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555a82e5-e56c-4075-a2a2-071633cd4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_SIZE = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f44ef-91d0-4d0e-afb5-a66240c9e1d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Q1.** In the following cell provide code to load the text file (each word is in a newline), then extract the words (in lowercase) into a list.\n",
    "\n",
    "For practical reasons of training the model we will only use words that are longer that $3$ letters and that have a maximum length of WORD_SIZE (this will be a constant we set at the beginning - you can change this and experiment with different WORD_SIZEs). As seen above it is set to $13$.\n",
    "\n",
    "So out of the extracted list of words filter out those words that match our criteria on word length.\n",
    "\n",
    "To train our model it is convenient to have words/strings of equal length. We will choose to convert every word to length of WORD_SIZE, by adding underscores to the end of the word if it is initially shorter than WORD_SIZE. For example, we will convert the word \"university\" (word length 10) into \"university___\" (wordlength 13). In your code include this conversion as well.\n",
    "\n",
    "Store the processed WORD_SIZE lengthed strings in a list called vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3219551c-a298-424a-a491-2d7f65a4ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaron________\n",
      "abandoned____\n",
      "aberdeen_____\n",
      "abilities____\n",
      "ability______\n",
      "able_________\n",
      "aboriginal___\n",
      "abortion_____\n",
      "about________\n",
      "above________\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "def prepare_vocabulary(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        words = [word.strip().lower() for word in file.readlines()]\n",
    "    \n",
    "    filtered_words = [word for word in words if 3 < len(word) <= WORD_SIZE]\n",
    "    vocab = [word.ljust(WORD_SIZE, '_') for word in filtered_words]\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "file_path = 'wordlist.txt'\n",
    "vocab = prepare_vocabulary(file_path)\n",
    "\n",
    "for i in range(10):\n",
    "    print(vocab[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3a6fe-c0a7-4808-aa1a-4c3ad6db6de3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='blue'>In the above explanation it was mentioned \"for practical reasons of training the model we will only use words that are longer that $3$ letters and that have a certain maximum length\". In your opinion what could be those practical? Will hit help to build a better model?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf86cdd-96b2-40eb-8230-c3f04e93cfc4",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "<font color='green'>\n",
    "\n",
    "The practical reason for using words longer than 3 letters and limiting the maximum length is to make the training process easier and more efficient.\n",
    "\n",
    "1) Short words are too simple: Words with 1-3 letters (like \"cat\" or \"the\") are too short to learn meaningful patterns. These words donâ€™t give the model much useful information for understanding how letters relate to each other.\n",
    "\n",
    "2) Long words add complexity: If we allow very long words, the model becomes harder to train because it has to handle more possibilities and remember longer sequences. This can make training slower and increase errors.\n",
    "\n",
    "By focusing on words between 4 and 13 letters, we keep a balance, the model gets enough information to learn meaningful patterns without being overwhelmed by too much complexity. This helps the model perform better in predicting word completions.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b2e6d-f771-4782-8b21-73c121565faa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Q2** To input words into the model, we will need to convert each letter/character into a number. as we have seen above, the only characters in our list vocab will be the underscore and lowercase english letters. so we will convert these $27$ characters into numbers as follows: underscore -> $0$, 'a' -> $1$, 'b' -> $2$, $\\cdots$, 'z' -> $26$. In the following cell,\n",
    "\n",
    "(i) Implement a method called char_to_num, that takes in a valid character and outputs its numerical assignment.\n",
    "\n",
    "(ii) Implement a method called num_to_char, that takes in a valid number from $0$ to $26$ and outputs the corresponding character.\n",
    "\n",
    "(iii) Implement a method called word_to_numlist, that takes in a word from our vocabulary and outputs a (torch) tensor of numbers that corresponds to each character in the word in that order. For example: the word \"united_______\" will be converted to tensor([21, 14,  9, 20,  5,  4,  0,  0,  0,  0,  0,  0,  0]). You are encouraged to use your char_to_num method for this.\n",
    "\n",
    "(iv) Implement a method called numlist_to_word, that does the opposite of the above described word_to_numlist, given a tensor of numbers from $0$ to $26$, outputs the corresponding word. You are encouraged to use your  num_to_char method for this.\n",
    "\n",
    "Note: As mentioned since we are using the torch library we will be using tensors instead of the usual python lists or numpy arrays. Tensors are the list equivalent in torch. Torch models only accept tensors as input and they output tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054a4ab4-5883-4948-adc5-eb8916b6234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_num(char):\n",
    "\n",
    "    #TODO\n",
    "    if char == '_':\n",
    "        num = 0\n",
    "    elif char.isalpha() and char.islower():\n",
    "        num = ord(char) - ord('a') + 1\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid character: {char}\")\n",
    "\n",
    "    return(num)\n",
    "\n",
    "def num_to_char(num):\n",
    "\n",
    "    #TODO\n",
    "    if num == 0:\n",
    "        char = '_'\n",
    "    elif 0 < num <= 26:\n",
    "        char = chr(num + ord('a') - 1)\n",
    "    else:\n",
    "        raise ValueError(f\"Out of range number: {num}\")\n",
    "\n",
    "    return(char)\n",
    "\n",
    "def word_to_numlist(word):\n",
    "\n",
    "    #TODO\n",
    "    numlist = torch.tensor([char_to_num(char) for char in word])\n",
    "\n",
    "    return(numlist)\n",
    "\n",
    "def numlist_to_word(numlist):\n",
    "\n",
    "    #TODO\n",
    "    word = ''.join(num_to_char(num.item()) for num in numlist)\n",
    "\n",
    "    return(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d1936-fadb-4ddb-9027-3a75960aa6b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font color='blue'>We convert letter into just numbers based on their aphabetical order, I claim that it is a very bad way to encode data such as letters to be fed into learning models, please write your explanation to or against my claim. If you are searching for reasons, the keyword 'categorical data' may be useful. Although the letters in our case are not treated as categorical data, the same reasons as for categorical data is applicable. Even if my claim is valid, at the end it won't matter due to something called \"embedding layers\" that we will use in our model. What is an embedding layer? What is it's purpose? Explain.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de3f69-cd06-4adc-8150-2522802f345a",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "<font color='green'>\n",
    "\n",
    "Converting letters into numbers based on their alphabetical order (such as 'a' -> 1, 'b' -> 2, etc.) is indeed a bad way to encode letters for a learning model. This is because there is no meaningful relationship between the numerical values assigned to the letters. For example, just because 'a' is assigned 1 and 'b' is assigned 2, it doesnâ€™t mean that 'b' is \"greater\" or \"closer\" to 'a' in any meaningful way for a machine learning model. This is the same problem we encounter with categorical data: categories like \"apple\" and \"orange\" shouldnâ€™t have a natural order like numbers do, so simply assigning them numbers can mislead the model into thinking that there is some kind of relationship between these numbers.\n",
    "\n",
    "Even though this claim is valid, it won't be an issue in our case because we will use something called an embedding layer. An embedding layer maps each letter to a dense vector in a continuous space. These vectors are learned during training, and they help the model understand relationships between letters in a more meaningful way. For example, letters that often appear together in words will have vectors that are closer to each other, while letters that donâ€™t have much in common will have vectors that are farther apart.\n",
    "\n",
    "So, while simple numerical encoding is not ideal, the embedding layer will learn and adjust the representations, allowing the model to perform better.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92070a74-0f42-435d-a3ba-b38f0d1aaf3c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Section 2: Implementing the Autocomplete model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb965e-afcd-41ae-86f0-2f3d4682e18b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will implement a RNN model based on LSTM. The [video tutorial](https://www.youtube.com/watch?v=tL5puCeDr-o) will be useful. Our model will be only one hidden layer, but feel free to sophisticate with more layers after the project for your own experiments.\n",
    "\n",
    "Our model will contain all the training and prediction methods as single package in a class (autocompleteModel) we will define and implement below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfe311c-669d-4d58-a833-ae3970b6d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4976fc91-2c4e-497a-954e-9014dd31be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autocompleteModel(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, alphabet_size, embed_dim, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set the input parameters to self parameters\n",
    "        self.alphabet_size = alphabet_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize the layers in the model\n",
    "        #1 embedding layer, 1 - LSTM cell (hidden layer), 1 fully connected layer with linear activation\n",
    "        self.embed_layer = nn.Embedding(self.alphabet_size, self.embed_dim)\n",
    "        self.LSTM = nn.LSTM(self.embed_dim, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.alphabet_size)\n",
    "\n",
    "    # Feedforward\n",
    "    def forward(self, character, hidden_state, cell_state):\n",
    "        #Perform feedforward in order\n",
    "        #1. Embed the input (one charcter represented by a number)\n",
    "        #2. Feed the embedded output to the LSTM cell\n",
    "        #3. Feed the LSTM output to the fully connected layer to obtain the output\n",
    "        #4. return the output, and both the hidden state and cell state from the LSTM cell output\n",
    "        embedding = self.embed_layer(character)\n",
    "        lstm_out, (hidden_state, cell_state) = self.LSTM(embedding.view(1, 1, -1), (hidden_state, cell_state))\n",
    "        output = self.fc(lstm_out.view(1, -1))\n",
    "        return output, hidden_state, cell_state\n",
    "\n",
    "    #Intialize the first hidden state and cell state (for the start of a word) as zero tensors of required length.\n",
    "    def initial_state(self):\n",
    "        h0 = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "        return (h0, c0)\n",
    "\n",
    "    #Train the model in epochs given the vocab, the training will be fed in batches of batch_size\n",
    "    def trainModel(self, vocab, epochs=5, batch_size=100):\n",
    "\n",
    "        #Convert the model into train mode\n",
    "        self.train()\n",
    "        #Set the optimizer (ADAM), you may need to provide the model parameters  and learning rate\n",
    "        optimizer = optim.Adam(self.parameters(), lr=LEARNING_RATE)\n",
    "        #Keep a log of the loss at the end of each training cycle.\n",
    "        loss_log = []\n",
    "\n",
    "        for e in range(epochs):\n",
    "\n",
    "            #TODO: Shuffle the vocab list the start of each epoch\n",
    "            random.shuffle(vocab)\n",
    "            num_iter = len(vocab) // batch_size\n",
    "            batch_loss_list = []\n",
    "\n",
    "            for i in tqdm(range(num_iter), desc=f\" Training - Epoch {e + 1}/{epochs} \", unit=\"batch\"):\n",
    "\n",
    "                #TODO: Set the loss to zero, initialize the optimizer with zero_grad at the beginning of each training cycle.\n",
    "                batch_loss = 0\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Extract the batch\n",
    "                vocab_batch = vocab[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "                for word in vocab_batch:\n",
    "                    #TODO: Initialize the hidden state and cell state at the start of each word.\n",
    "                    hidden_state, cell_state = self.initial_state()\n",
    "\n",
    "                    #TODO: Convert the word into a tensor of number and create input and target from the word\n",
    "                    #Input will be the first WORD_SIZE - 1 charcters and target is the last WORD_SIZE - 1 charcters\n",
    "                    input_tensor = word_to_numlist(word[:WORD_SIZE - 1])\n",
    "                    target_tensor = word_to_numlist(word[1:WORD_SIZE])\n",
    "\n",
    "                    # Loop through each character in the word\n",
    "                    for c in range(WORD_SIZE - 1):\n",
    "                        #TODO: Feed the cth character to the model (feedforward) and comput the loss (use cross entropy in torch)\n",
    "                        output, hidden_state, cell_state = self.forward(input_tensor[c].unsqueeze(0), hidden_state, cell_state)\n",
    "                        loss = nn.functional.cross_entropy(output, target_tensor[c].view(1))\n",
    "                        batch_loss += loss\n",
    "\n",
    "                #TODO: Compute the average loss per word in the batch and perform backpropagation (.backward())\n",
    "                batch_loss /= len(vocab_batch)\n",
    "                batch_loss.backward()\n",
    "\n",
    "                #TODO: Update model parameters using the optimizer\n",
    "                optimizer.step()\n",
    "                #Update the loss_log \n",
    "                batch_loss_list.append(batch_loss.item())\n",
    "\n",
    "            print(\"Epoch: \", e + 1, \" Training loss per word : \", batch_loss.item())\n",
    "            loss_log.append(np.mean(batch_loss_list))\n",
    "\n",
    "        #TODO Plot a graph of the variation of the loss.\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(loss_log)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss vs Epochs')\n",
    "        plt.show()\n",
    "\n",
    "    #Perform autocmplete given a sample of strings (typically 3-5 starting letters)\n",
    "    def autocomplete(self, sample):\n",
    "        #Convert the model into evaluation mode\n",
    "        self.eval()\n",
    "        completed_list = []\n",
    "\n",
    "        #TODO: In the following loop for each sample item initialize hidden and cell states, then predict the remaining characters\n",
    "        for i in tqdm(range(len(sample)), desc=\"Prediction\", unit=\"word\"):\n",
    "            literal = sample[i]\n",
    "            hidden_state, cell_state = self.initial_state()\n",
    "            input_tensor = word_to_numlist(literal)\n",
    "            predicted = literal\n",
    "\n",
    "            for p in range(len(literal) - 1):\n",
    "                init_input = input_tensor[p].unsqueeze(0)\n",
    "                _, hidden_state, cell_state = self.forward(init_input, hidden_state, cell_state)\n",
    "\n",
    "            init_input = input_tensor[-1].unsqueeze(0)\n",
    "\n",
    "            #You will have to convert the output into a softmax (you may use your softmax method from the last project) probability distribution, then use torch.multinomial \n",
    "            for g in range(WORD_SIZE):\n",
    "                output, hidden_state, cell_state = self.forward(init_input, hidden_state, cell_state)\n",
    "                output_prob = nn.functional.softmax(output, dim=1)\n",
    "                top_1 = torch.multinomial(output_prob, 1)[0]\n",
    "                pred_char = num_to_char(top_1.item())\n",
    "                predicted += pred_char\n",
    "                init_input = torch.tensor(char_to_num(pred_char)).unsqueeze(0)\n",
    "\n",
    "            completed_list.append(predicted)\n",
    "\n",
    "        return(completed_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b5489-b770-4519-b20c-4f2beebfb8f9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Section 3: Using and evaluating the model\n",
    "\n",
    "(i) Feel free to initialize a autocompleteModel using different embedding dimensions and hidden layer sizes. Use different learning rates, epochs, batch sizes. Train the best model you can. Show the loss curves in you answers.\n",
    "\n",
    "(ii) Evaluate it on different samples of partially filled in words. Eg: [\"univ\", \"math\", \"neur\", \"engin\"] etc. Please show outputs for different samples.\n",
    "\n",
    "<font color='blue'>Comment on the results. Is it successful? Do you see familiar substrings in the generated tesxt such as \"tion\", \"ing\", \"able\" etc. What are your suggestions to improve the model?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e16d6b-6460-4fce-8757-aac766683e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autocompleteModel( alphabet_size = 27 ,\n",
    "                           embed_dim = 100, \n",
    "                           hidden_size = 128, \n",
    "                           num_layers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b96919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 1/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:28<00:00,  1.00s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Training loss per word :  14.568717002868652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 2/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:34<00:00,  1.07s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  Training loss per word :  14.169864654541016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 3/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:35<00:00,  1.09s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  Training loss per word :  13.524555206298828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 4/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:36<00:00,  1.10s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  Training loss per word :  13.2160062789917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 5/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:35<00:00,  1.09s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5  Training loss per word :  13.305241584777832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 6/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:35<00:00,  1.08s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6  Training loss per word :  11.641826629638672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 7/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:34<00:00,  1.08s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7  Training loss per word :  11.182146072387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 8/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:37<00:00,  1.10s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8  Training loss per word :  11.243267059326172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 9/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:35<00:00,  1.08s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9  Training loss per word :  11.235906600952148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 10/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:36<00:00,  1.09s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10  Training loss per word :  10.815437316894531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 11/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:38<00:00,  1.12s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11  Training loss per word :  10.749048233032227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 12/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:36<00:00,  1.09s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12  Training loss per word :  10.433521270751953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 13/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:34<00:00,  1.08s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13  Training loss per word :  9.902721405029297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 14/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:39<00:00,  1.13s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14  Training loss per word :  10.618120193481445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 15/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:37<00:00,  1.11s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15  Training loss per word :  10.213113784790039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 16/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:43<00:00,  1.17s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16  Training loss per word :  9.655303001403809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 17/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:42<00:00,  1.16s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17  Training loss per word :  9.821187019348145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 18/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:35<00:00,  1.08s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18  Training loss per word :  9.413468360900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 19/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:34<00:00,  1.07s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19  Training loss per word :  9.875690460205078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Training - Epoch 20/20 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:35<00:00,  1.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20  Training loss per word :  9.548742294311523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.trainModel(vocab = vocab, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1f74076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 144.22word/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['universe_________',\n",
       " 'mathelled________',\n",
       " 'neural___________',\n",
       " 'engineer__________']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.autocomplete([\"univ\", \"math\", \"neur\", \"engin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95a59450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 133.63word/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['equal____________',\n",
       " 'excellent________',\n",
       " 'improvings_______',\n",
       " 'general___________',\n",
       " 'translation________',\n",
       " 'valuation________']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.autocomplete([\"equa\", \"exce\", \"impr\", \"gener\", \"transl\", \"valu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae17c8",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "Results Analysis:\n",
    "\n",
    "\"univ\" â†’ \"universe_________\"\n",
    "The completion of \"univ\" to \"universe\" is accurate and relevant, suggesting the model learned the correct continuation.\n",
    "\n",
    "\"math\" â†’ \"mathelled________\"\n",
    "This result is less satisfactory. \"Mathelled\" is not a valid word, and the model might be struggling to find a familiar continuation for \"math.\"\n",
    "\n",
    "\"neur\" â†’ \"neural___________\"\n",
    "\"Neural\" is a valid word and a correct prediction. The model likely learned medical or biological terminology.\n",
    "\n",
    "\"engin\" â†’ \"engineer__________\"\n",
    "\"Engineer\" is a sensible completion and correct.\n",
    "\n",
    "\"equa\" â†’ \"equal____________\"\n",
    "\"Equal\" is a correct and valid word completion.\n",
    "\n",
    "\"exce\" â†’ \"excellent________\"\n",
    "\"Excellent\" is another correct prediction, which is highly relevant.\n",
    "\n",
    "\"impr\" â†’ \"improvings_______\"\n",
    "The prefix \"impr\" is correctly continued with \"improvings,\" though this is grammatically incorrect. It might have been expected to generate \"improvement\" or \"improving.\"\n",
    "\n",
    "\"gener\" â†’ \"general___________\"\n",
    "\"General\" is a common and valid word completion.\n",
    "\n",
    "\"transl\" â†’ \"translation________\"\n",
    "\"Translation\" is a proper completion, matching the expected pattern.\n",
    "\n",
    "\"valu\" â†’ \"valuation________\"\n",
    "\"Valuation\" is a valid and correct completion.\n",
    "\n",
    "Familiar Substrings\n",
    "- We do see familiar substrings like \"tion\" in \"translation\" and \"valuation\" as well as \"ing\" in \"improvings\". However, there are issues in words like \"mathelled\" and \"improvings,\" where the model generates inaccurate endings.\n",
    "\n",
    "Suggestions for Improvement\n",
    "- Train longer: Increase the number of training epochs to help the model learn better word patterns.\n",
    "\n",
    "- Improve training data: Use a larger and more varied dataset to help the model predict words more accurately.\n",
    "\n",
    "- Use pretrained embeddings: Try using word embeddings like GloVe or FastText, which already know many words and their meanings.\n",
    "\n",
    "- Add dropout: Include dropout layers in the model to prevent it from memorizing specific patterns and help it generalize better.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451a8a14",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "fffff532a40ef30061b2c21fbdf0ad63dbbec83c48bfab354e8a499d7b348239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
